{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-size: 40px;\">\n",
    "    <b>Final Project</b>\n",
    "    <br>\n",
    "    Mouad ID SOUGOU\n",
    "    <br>\n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "from MarkovianTechniques import FixedMarkovianBased, VariableMarkovianBased, SparseMarkovRIPPER, SparseMarkovTransducer\n",
    "import os \n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro : Generating Synthetic Data :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data we tried to find online for synthetic timeseries was rarely labeled, we propose to generate some synthetic data so that we can test and implement as many algorithm for our discreet anomaly detection library. We can then test our algorithm on some real, less labeled data.\n",
    "\n",
    "### Markovian models :     \n",
    "\n",
    "This class will generate synthetic data that creates Markovian Discreet sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHABET = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarkovianSequences: \n",
    "    def __init__(self, transition_matrix, hidden_matrix=None, n_sequences=100, sequence_length=50): \n",
    "        self.transition_matrix = transition_matrix\n",
    "        self.n_symbols = len(transition_matrix)\n",
    "        self.symbols = ALPHABET[:self.n_symbols]\n",
    "        self.sequence_length = sequence_length\n",
    "        self.n_sequences = n_sequences\n",
    "        self.hidden_matrix = hidden_matrix\n",
    "        self.check_probabilities()\n",
    "    \n",
    "    def check_probabilities(self): \n",
    "        for i in range(self.transition_matrix.shape[0]):\n",
    "            if not np.isclose(np.sum(self.transition_matrix[i]), 1.0):\n",
    "                raise ValueError(f\"Row {i} of transition_matrix does not sum to 1.\")\n",
    "\n",
    "        if self.hidden_matrix is not None:\n",
    "            if self.hidden_matrix.shape[0] != self.hidden_matrix.shape[1]:\n",
    "                raise ValueError(\"hidden_matrix must be square.\")\n",
    "            for i in range(self.hidden_matrix.shape[0]):\n",
    "                if not np.isclose(np.sum(self.hidden_matrix[i]), 1.0):\n",
    "                    raise ValueError(f\"Row {i} of hidden_matrix does not sum to 1.\")\n",
    "            self.n_hidden = self.hidden_matrix.shape[0]\n",
    "            if self.n_hidden != self.transition_matrix.shape[0]:\n",
    "                raise ValueError(\"Number of hidden states does not match the dimension of transition_matrix.\")\n",
    "            \n",
    "    def generate_sequence(self, initial_state=None): \n",
    "        if initial_state is None:\n",
    "            current_state = np.random.choice(self.n_symbols)\n",
    "        else:\n",
    "            current_state = initial_state\n",
    "\n",
    "        sequence = [self.symbols[current_state]]\n",
    "        for _ in range(self.sequence_length - 1):\n",
    "            next_state = np.random.choice(self.n_symbols, p=self.transition_matrix[current_state])\n",
    "            sequence.append(self.symbols[next_state])\n",
    "            current_state = next_state\n",
    "        return sequence\n",
    "    \n",
    "    def generate_hidden_sequence(self, initial_state=None):       \n",
    "        if initial_state is None:\n",
    "            current_hidden_state = np.random.choice(self.n_hidden)\n",
    "        else:\n",
    "            current_hidden_state = initial_state\n",
    "\n",
    "        current_symbol = np.random.choice(self.n_symbols, p=self.transition_matrix[current_hidden_state])\n",
    "        sequence = [self.symbols[current_symbol]]\n",
    "\n",
    "        for _ in range(self.sequence_length - 1):\n",
    "            next_hidden_state = np.random.choice(self.n_hidden, p=self.hidden_matrix[current_hidden_state])\n",
    "            emitted_symbol = np.random.choice(self.n_symbols, p=self.transition_matrix[next_hidden_state])\n",
    "            sequence.append(self.symbols[emitted_symbol])\n",
    "            current_hidden_state = next_hidden_state\n",
    "\n",
    "        return sequence\n",
    "\n",
    "    def generate_all_sequences(self):\n",
    "        all_seqs = []\n",
    "        for _ in range(self.n_sequences):\n",
    "            if self.hidden_matrix is not None: \n",
    "                seq = self.generate_hidden_sequence()\n",
    "            else: \n",
    "                seq = self.generate_sequence()\n",
    "            all_seqs.append(seq)\n",
    "        return all_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarkovianDatasetGenerator: \n",
    "    def __init__(self, transition_matrices, hidden_matrices, n_sequences=100, sequence_length=50): \n",
    "        self.transition_matrices = transition_matrices\n",
    "        self.hidden_matrices = hidden_matrices \n",
    "        self.n_sequences = n_sequences\n",
    "        self.sequence_length = sequence_length\n",
    "        self.generators = self.init_transform()\n",
    "    \n",
    "    def init_transform(self):\n",
    "        self.generators = []\n",
    "        self.dataset = []\n",
    "        for transition_matrix, hidden_matrix in zip(self.transition_matrices, self.hidden_matrices): \n",
    "            generator = MarkovianSequences(transition_matrix, \n",
    "                                           hidden_matrix=hidden_matrix, \n",
    "                                           n_sequences=self.n_sequences, \n",
    "                                           sequence_length=self.sequence_length) \n",
    "            self.generators.append(generator)\n",
    "        return self.generators\n",
    "\n",
    "    def generate(self): \n",
    "        self.dataset = []\n",
    "        for generator in self.generators: \n",
    "            sequences = generator.generate_all_sequences()\n",
    "            self.dataset.extend(sequences)\n",
    "\n",
    "        return self.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first generate synthetic data from the given transition matrix\n",
    "transition_matrix = np.array([\n",
    "    [0.1, 0.6, 0.3],\n",
    "    [0.4, 0.4, 0.2],\n",
    "    [0.2, 0.3, 0.5]\n",
    "])\n",
    "markov_generator = MarkovianSequences(transition_matrix, n_sequences=100, sequence_length=50)\n",
    "train_sequences = markov_generator.generate_all_sequences()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III) Markovian Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Fixed Markovian Techniques \n",
    "\n",
    "This technique “learns” the conditional probability of occurrence of a given symbol using a given fixed history $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the Markovian anomaly detector\n",
    "detector_fixed = FixedMarkovianBased(k=3)  # History length k = 3\n",
    "detector_fixed.train(train_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Sequence: ['B', 'C', 'C', 'C', 'C', 'C', 'A']\n",
      "Anomaly Score for the Test Sequence: 68.65714865662405\n"
     ]
    }
   ],
   "source": [
    "test_sequence = train_sequences[0][20:27]\n",
    "print(f\"\\nTest Sequence: {test_sequence}\")\n",
    "\n",
    "# Compute the anomaly score for the test sequence\n",
    "anomaly_score = detector_fixed.compute_anomaly_score(test_sequence)\n",
    "print(f\"Anomaly Score for the Test Sequence: {anomaly_score}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Sequence: ['A', 'B', 'A', 'C', 'B', 'A', 'A']\n",
      "Anomaly Score for the Test Sequence: 786.2371221940447\n"
     ]
    }
   ],
   "source": [
    "test_sequence = ['A', 'B', 'A', 'C', 'B', 'A', 'A']\n",
    "print(f\"\\nTest Sequence: {test_sequence}\")\n",
    "\n",
    "# Compute the anomaly score for the test sequence\n",
    "anomaly_score = detector_fixed.compute_anomaly_score(test_sequence)\n",
    "print(f\"Anomaly Score for the Test Sequence: {anomaly_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first try it on a sequence from the train set, and then on a different one. The higher anomaly scores indicate greater anomaly likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Variable Markovian Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This technique addresses a key limitation of fixed Markov models. Instead of always using a context of size \n",
    "$k-1$, it dynamically adjusts the size of the context. Variable Markovian techniques solve the problem of rare contexts which is a disadvantage of the fixed techniques, if a context is rare in the training data, its probability will be very low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_variable = VariableMarkovianBased(max_depth=3)\n",
    "detector_variable.train(train_sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Sequence: ['B', 'C', 'C', 'C', 'C', 'C', 'A']\n",
      "Anomaly Score for the Test Sequence: 5.992480162952356\n"
     ]
    }
   ],
   "source": [
    "test_sequence = train_sequences[0][20:27]\n",
    "print(f\"\\nTest Sequence: {test_sequence}\")\n",
    "\n",
    "# Compute the anomaly score for the test sequence\n",
    "anomaly_score = detector_variable.compute_anomaly_score(test_sequence)\n",
    "print(f\"Anomaly Score for the Test Sequence: {anomaly_score}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly Score for Test Sequence ['A', 'B', 'C', 'D', 'E', 'F']: 22.853816272508112\n"
     ]
    }
   ],
   "source": [
    "# Test sequence\n",
    "test_sequence = ['A', 'B', 'C', 'D', 'E', 'F']\n",
    "anomaly_score = detector_variable.compute_anomaly_score(test_sequence)\n",
    "print(f\"Anomaly Score for Test Sequence {test_sequence}: {anomaly_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Sparse Markovian Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This technique aim to increase flexibility compared to Fixed and Variable Markovian Techniques. The key difference is that instead of relying on **contiguous** and immediately preceding symbols as the context, Sparse Markovian Techniques allow for **gaps** or wildcards in the context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sparse Markovian Transducer technique\n",
    "The SMT method builds a sparse suffix tree where contexts can have wildcards and uses this tree to compute the probability of a sequence using context matching and backoff to shorter contexts when necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "smt = SparseMarkovTransducer(max_depth=3, wildcard_positions=[1])  # Wildcard at position 1\n",
    "for sequence in train_sequences:\n",
    "    smt.insert(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Sequence: ['B', 'B', 'B', 'C', 'C', 'C', 'A']\n",
      "Probability of Test Sequence: 0.0014916014206201528\n",
      "Anomaly Score of Test Sequence: 6.507904957246444\n"
     ]
    }
   ],
   "source": [
    "test_sequence = train_sequences[0][30:37]\n",
    "print(f\"\\nTest Sequence: {test_sequence}\")\n",
    "\n",
    "probability = smt.compute_sequence_probability(test_sequence)\n",
    "anomaly_score = smt.compute_anomaly_score(test_sequence)\n",
    "print(f\"Probability of Test Sequence: {probability}\")\n",
    "print(f\"Anomaly Score of Test Sequence: {anomaly_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Sequence: ['A', 'A', 'B', 'B', 'B', 'A', 'A']\n",
      "Probability of Test Sequence: 0.0003029588651361972\n",
      "Anomaly Score of Test Sequence: 8.101913520297353\n"
     ]
    }
   ],
   "source": [
    "test_sequence = ['A', 'A', 'B', 'B', 'B', 'A', 'A']\n",
    "print(f\"\\nTest Sequence: {test_sequence}\")\n",
    "\n",
    "probability = smt.compute_sequence_probability(test_sequence)\n",
    "anomaly_score = smt.compute_anomaly_score(test_sequence)\n",
    "print(f\"Probability of Test Sequence: {probability}\")\n",
    "print(f\"Anomaly Score of Test Sequence: {anomaly_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rule Based technique (**R**epeated **I**ncremental **P**runing to **P**roduce **E**rror **R**eduction)\n",
    "The RIPPER method extracts (context, next symbol) pairs from training sequences, encodes the symbols as numeric features, and trains a decision tree-based classifier to predict the next symbol for a given context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RIPPER-Based Sparse Markov ---\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- RIPPER-Based Sparse Markov ---\")\n",
    "ripper = SparseMarkovRIPPER(max_depth=3)\n",
    "ripper.train(train_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Sequence: ['B', 'B', 'B', 'C', 'C', 'C', 'A']\n",
      "Anomaly Score of Test Sequence: 14.026231589279927\n"
     ]
    }
   ],
   "source": [
    "test_sequence = train_sequences[0][30:37]\n",
    "print(f\"\\nTest Sequence: {test_sequence}\")\n",
    "\n",
    "anomaly_score_ripper = ripper.compute_anomaly_score(test_sequence)\n",
    "print(f\"Anomaly Score of Test Sequence: {anomaly_score_ripper}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Sequence: ['A', 'A', 'A', 'A', 'B', 'A', 'A']\n",
      "Test Sequence: ['A', 'A', 'A', 'A', 'B', 'A', 'A']\n",
      "Anomaly Score of Test Sequence: 20.82862635260424\n"
     ]
    }
   ],
   "source": [
    "test_sequence = ['A', 'A', 'A', 'A', 'B', 'A', 'A']\n",
    "print(f\"\\nTest Sequence: {test_sequence}\")\n",
    "\n",
    "anomaly_score_ripper = ripper.compute_anomaly_score(test_sequence)\n",
    "print(f\"Test Sequence: {test_sequence}\")\n",
    "print(f\"Anomaly Score of Test Sequence: {anomaly_score_ripper}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
